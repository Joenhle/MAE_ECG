cuda is True
device is cuda
conv1.weight
True
bn1.weight
True
bn1.bias
True
layer1.0.conv1.weight
True
layer1.0.bn1.weight
True
layer1.0.bn1.bias
True
layer1.0.conv2.weight
True
layer1.0.bn2.weight
True
layer1.0.bn2.bias
True
layer1.1.conv1.weight
True
layer1.1.bn1.weight
True
layer1.1.bn1.bias
True
layer1.1.conv2.weight
True
layer1.1.bn2.weight
True
layer1.1.bn2.bias
True
layer1.2.conv1.weight
True
layer1.2.bn1.weight
True
layer1.2.bn1.bias
True
layer1.2.conv2.weight
True
layer1.2.bn2.weight
True
layer1.2.bn2.bias
True
layer2.0.conv1.weight
True
layer2.0.bn1.weight
True
layer2.0.bn1.bias
True
layer2.0.conv2.weight
True
layer2.0.bn2.weight
True
layer2.0.bn2.bias
True
layer2.0.downsample.0.weight
True
layer2.0.downsample.1.weight
True
layer2.0.downsample.1.bias
True
layer2.1.conv1.weight
True
layer2.1.bn1.weight
True
layer2.1.bn1.bias
True
layer2.1.conv2.weight
True
layer2.1.bn2.weight
True
layer2.1.bn2.bias
True
layer2.2.conv1.weight
True
layer2.2.bn1.weight
True
layer2.2.bn1.bias
True
layer2.2.conv2.weight
True
layer2.2.bn2.weight
True
layer2.2.bn2.bias
True
layer2.3.conv1.weight
True
layer2.3.bn1.weight
True
layer2.3.bn1.bias
True
layer2.3.conv2.weight
True
layer2.3.bn2.weight
True
layer2.3.bn2.bias
True
layer3.0.conv1.weight
True
layer3.0.bn1.weight
True
layer3.0.bn1.bias
True
layer3.0.conv2.weight
True
layer3.0.bn2.weight
True
layer3.0.bn2.bias
True
layer3.0.downsample.0.weight
True
layer3.0.downsample.1.weight
True
layer3.0.downsample.1.bias
True
layer3.1.conv1.weight
True
layer3.1.bn1.weight
True
layer3.1.bn1.bias
True
layer3.1.conv2.weight
True
layer3.1.bn2.weight
True
layer3.1.bn2.bias
True
layer3.2.conv1.weight
True
layer3.2.bn1.weight
True
layer3.2.bn1.bias
True
layer3.2.conv2.weight
True
layer3.2.bn2.weight
True
layer3.2.bn2.bias
True
layer3.3.conv1.weight
True
layer3.3.bn1.weight
True
layer3.3.bn1.bias
True
layer3.3.conv2.weight
True
layer3.3.bn2.weight
True
layer3.3.bn2.bias
True
layer3.4.conv1.weight
True
layer3.4.bn1.weight
True
layer3.4.bn1.bias
True
layer3.4.conv2.weight
True
layer3.4.bn2.weight
True
layer3.4.bn2.bias
True
layer3.5.conv1.weight
True
layer3.5.bn1.weight
True
layer3.5.bn1.bias
True
layer3.5.conv2.weight
True
layer3.5.bn2.weight
True
layer3.5.bn2.bias
True
layer4.0.conv1.weight
True
layer4.0.bn1.weight
True
layer4.0.bn1.bias
True
layer4.0.conv2.weight
True
layer4.0.bn2.weight
True
layer4.0.bn2.bias
True
layer4.0.downsample.0.weight
True
layer4.0.downsample.1.weight
True
layer4.0.downsample.1.bias
True
layer4.1.conv1.weight
True
layer4.1.bn1.weight
True
layer4.1.bn1.bias
True
layer4.1.conv2.weight
True
layer4.1.bn2.weight
True
layer4.1.bn2.bias
True
layer4.2.conv1.weight
True
layer4.2.bn1.weight
True
layer4.2.bn1.bias
True
layer4.2.conv2.weight
True
layer4.2.bn2.weight
True
layer4.2.bn2.bias
True
fc.weight
True
fc.bias
True
ResNet(
  (conv1): Conv1d(1, 64, kernel_size=(15,), stride=(2,), padding=(7,), bias=False)
  (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (relu): ReLU(inplace=True)
  (maxpool): MaxPool1d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  (layer1): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (1): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (2): BasicBlock(
      (conv1): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(64, 64, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
  )
  (layer2): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(64, 128, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(64, 128, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (1): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (2): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (3): BasicBlock(
      (conv1): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(128, 128, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
  )
  (layer3): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(128, 256, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(128, 256, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (1): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (2): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (3): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (4): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (5): BasicBlock(
      (conv1): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(256, 256, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
  )
  (layer4): Sequential(
    (0): BasicBlock(
      (conv1): Conv1d(256, 512, kernel_size=(7,), stride=(2,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (downsample): Sequential(
        (0): Conv1d(256, 512, kernel_size=(1,), stride=(2,), bias=False)
        (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (1): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
    (2): BasicBlock(
      (conv1): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
      (conv2): Conv1d(512, 512, kernel_size=(7,), stride=(1,), padding=(3,), bias=False)
      (bn2): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (dropout): Dropout(p=0.2, inplace=False)
    )
  )
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (fc): Linear(in_features=512, out_features=7, bias=True)
)  0%|          | 0/1000 [00:00<?, ?it/s]
train_datasize 3778 val_datasize 947
  0%|          | 1/1000 [00:23<6:35:36, 23.76s/it]#epoch:01 stage:1 train_loss:1.520e+02 val_loss:3.927e+01  time:0m24s

 
  0%|          | 2/1000 [00:46<6:28:47, 23.37s/it]#epoch:02 stage:1 train_loss:1.313e+02 val_loss:3.843e+01  time:0m22s

 
  0%|          | 3/1000 [01:08<6:24:09, 23.12s/it]#epoch:03 stage:1 train_loss:1.222e+02 val_loss:3.556e+01  time:0m22s

 
  0%|          | 4/1000 [01:31<6:20:46, 22.94s/it]#epoch:04 stage:1 train_loss:1.196e+02 val_loss:2.652e+01  time:0m22s

 
  0%|          | 5/1000 [01:53<6:18:12, 22.81s/it]#epoch:05 stage:1 train_loss:1.202e+02 val_loss:2.547e+01  time:0m22s

 
  1%|          | 6/1000 [02:16<6:16:26, 22.72s/it]#epoch:06 stage:1 train_loss:1.285e+02 val_loss:9.194e+01  time:0m22s

 
  1%|          | 7/1000 [02:38<6:14:32, 22.63s/it]#epoch:07 stage:1 train_loss:1.240e+02 val_loss:2.659e+01  time:0m22s

 
  1%|          | 8/1000 [03:01<6:13:16, 22.58s/it]#epoch:08 stage:1 train_loss:1.137e+02 val_loss:3.011e+01  time:0m22s

 
  1%|          | 9/1000 [03:23<6:12:40, 22.56s/it]#epoch:09 stage:1 train_loss:1.233e+02 val_loss:2.576e+01  time:0m22s

 
  1%|          | 10/1000 [03:46<6:12:03, 22.55s/it]#epoch:10 stage:1 train_loss:1.228e+02 val_loss:2.636e+01  time:0m22s

 
  1%|          | 11/1000 [04:08<6:10:28, 22.48s/it]#epoch:11 stage:1 train_loss:1.243e+02 val_loss:3.200e+01  time:0m22s

 
  1%|          | 12/1000 [04:30<6:10:00, 22.47s/it]#epoch:12 stage:1 train_loss:1.240e+02 val_loss:3.498e+01  time:0m22s

 
  1%|▏         | 13/1000 [04:53<6:09:35, 22.47s/it]#epoch:13 stage:1 train_loss:1.217e+02 val_loss:2.577e+01  time:0m22s

 
  1%|▏         | 14/1000 [05:15<6:07:57, 22.39s/it]#epoch:14 stage:1 train_loss:1.153e+02 val_loss:3.436e+01  time:0m22s

 
  2%|▏         | 15/1000 [05:38<6:08:33, 22.45s/it]#epoch:15 stage:1 train_loss:1.148e+02 val_loss:2.620e+01  time:0m22s

 
  2%|▏         | 16/1000 [06:00<6:08:44, 22.48s/it]#epoch:16 stage:1 train_loss:1.131e+02 val_loss:2.554e+01  time:0m22s

 
  2%|▏         | 17/1000 [06:23<6:08:27, 22.49s/it]#epoch:17 stage:1 train_loss:1.120e+02 val_loss:2.529e+01  time:0m22s

 
  2%|▏         | 18/1000 [06:45<6:08:28, 22.51s/it]#epoch:18 stage:1 train_loss:1.114e+02 val_loss:2.500e+01  time:0m22s

 
  2%|▏         | 19/1000 [07:08<6:08:32, 22.54s/it]#epoch:19 stage:1 train_loss:1.110e+02 val_loss:2.486e+01  time:0m22s

 
  2%|▏         | 20/1000 [07:30<6:07:54, 22.52s/it]#epoch:20 stage:1 train_loss:1.108e+02 val_loss:2.481e+01  time:0m22s

 
  2%|▏         | 21/1000 [07:53<6:07:42, 22.54s/it]#epoch:21 stage:1 train_loss:1.105e+02 val_loss:2.451e+01  time:0m22s

 
  2%|▏         | 22/1000 [08:15<6:06:51, 22.51s/it]#epoch:22 stage:1 train_loss:1.102e+02 val_loss:2.443e+01  time:0m22s

 
  2%|▏         | 23/1000 [08:38<6:06:28, 22.51s/it]#epoch:23 stage:1 train_loss:1.101e+02 val_loss:2.433e+01  time:0m22s

 
  2%|▏         | 24/1000 [09:01<6:06:47, 22.55s/it]#epoch:24 stage:1 train_loss:1.092e+02 val_loss:2.399e+01  time:0m22s

 
  2%|▎         | 25/1000 [09:23<6:06:19, 22.54s/it]#epoch:25 stage:1 train_loss:1.101e+02 val_loss:2.425e+01  time:0m22s

 
  3%|▎         | 26/1000 [09:46<6:06:13, 22.56s/it]#epoch:26 stage:1 train_loss:1.093e+02 val_loss:2.372e+01  time:0m22s

 
  3%|▎         | 27/1000 [10:08<6:05:51, 22.56s/it]#epoch:27 stage:1 train_loss:1.090e+02 val_loss:2.340e+01  time:0m22s

 
  3%|▎         | 28/1000 [10:31<6:05:06, 22.54s/it]#epoch:28 stage:1 train_loss:1.116e+02 val_loss:2.335e+01  time:0m22s

 
  3%|▎         | 29/1000 [10:53<6:04:28, 22.52s/it]#epoch:29 stage:1 train_loss:1.077e+02 val_loss:2.229e+01  time:0m22s

 
  3%|▎         | 30/1000 [11:16<6:03:35, 22.49s/it]#epoch:30 stage:1 train_loss:1.071e+02 val_loss:2.284e+01  time:0m22s

 
  3%|▎         | 31/1000 [11:38<6:02:55, 22.47s/it]#epoch:31 stage:1 train_loss:1.090e+02 val_loss:2.291e+01  time:0m22s

 
  3%|▎         | 32/1000 [12:01<6:03:11, 22.51s/it]#epoch:32 stage:1 train_loss:1.048e+02 val_loss:2.211e+01  time:0m22s

 
  3%|▎         | 33/1000 [12:23<6:02:57, 22.52s/it]#epoch:33 stage:1 train_loss:1.044e+02 val_loss:2.254e+01  time:0m22s

 
  3%|▎         | 34/1000 [12:46<6:02:00, 22.48s/it]#epoch:34 stage:1 train_loss:9.944e+01 val_loss:2.338e+01  time:0m22s

 
  4%|▎         | 35/1000 [13:08<6:01:20, 22.47s/it]#epoch:35 stage:1 train_loss:9.712e+01 val_loss:2.354e+01  time:0m22s

 
  4%|▎         | 36/1000 [13:31<6:01:14, 22.48s/it]#epoch:36 stage:1 train_loss:1.002e+02 val_loss:2.303e+01  time:0m22s

 
  4%|▎         | 37/1000 [13:53<6:00:23, 22.45s/it]#epoch:37 stage:1 train_loss:9.658e+01 val_loss:2.531e+01  time:0m22s

 
  4%|▍         | 38/1000 [14:16<6:01:14, 22.53s/it]#epoch:38 stage:1 train_loss:9.949e+01 val_loss:2.203e+01  time:0m22s

 
  4%|▍         | 39/1000 [14:38<6:01:45, 22.59s/it]#epoch:39 stage:1 train_loss:9.283e+01 val_loss:2.174e+01  time:0m22s

 
  4%|▍         | 40/1000 [15:01<6:00:07, 22.51s/it]#epoch:40 stage:1 train_loss:8.630e+01 val_loss:2.558e+01  time:0m22s

 
  4%|▍         | 41/1000 [15:23<5:59:41, 22.50s/it]#epoch:41 stage:1 train_loss:8.590e+01 val_loss:2.398e+01  time:0m22s

 
  4%|▍         | 42/1000 [15:46<5:59:47, 22.53s/it]#epoch:42 stage:1 train_loss:8.209e+01 val_loss:2.160e+01  time:0m22s

 
  4%|▍         | 43/1000 [16:08<5:59:10, 22.52s/it]#epoch:43 stage:1 train_loss:7.910e+01 val_loss:2.195e+01  time:0m22s

 
  4%|▍         | 44/1000 [16:31<5:57:57, 22.47s/it]#epoch:44 stage:1 train_loss:7.096e+01 val_loss:2.226e+01  time:0m22s

 
  4%|▍         | 45/1000 [16:53<5:57:39, 22.47s/it]#epoch:45 stage:1 train_loss:6.735e+01 val_loss:2.219e+01  time:0m22s

 
  5%|▍         | 46/1000 [17:16<5:57:27, 22.48s/it]#epoch:46 stage:1 train_loss:6.572e+01 val_loss:2.170e+01  time:0m22s

 
  5%|▍         | 47/1000 [17:38<5:57:18, 22.50s/it]#epoch:47 stage:1 train_loss:6.405e+01 val_loss:2.142e+01  time:0m22s

 
  5%|▍         | 48/1000 [18:01<5:57:26, 22.53s/it]#epoch:48 stage:1 train_loss:6.067e+01 val_loss:2.094e+01  time:0m22s

 
  5%|▍         | 49/1000 [18:23<5:56:24, 22.49s/it]#epoch:49 stage:1 train_loss:6.138e+01 val_loss:2.120e+01  time:0m22s

 
  5%|▌         | 50/1000 [18:46<5:56:21, 22.51s/it]#epoch:50 stage:1 train_loss:6.800e+01 val_loss:2.077e+01  time:0m22s

 
  5%|▌         | 51/1000 [19:08<5:56:24, 22.53s/it]#epoch:51 stage:1 train_loss:6.187e+01 val_loss:2.045e+01  time:0m22s

 
  5%|▌         | 52/1000 [19:31<5:56:40, 22.57s/it]#epoch:52 stage:1 train_loss:5.310e+01 val_loss:2.037e+01  time:0m22s

 
  5%|▌         | 53/1000 [19:54<5:56:09, 22.57s/it]#epoch:53 stage:1 train_loss:5.094e+01 val_loss:1.994e+01  time:0m22s

 
  5%|▌         | 54/1000 [20:16<5:55:55, 22.57s/it]#epoch:54 stage:1 train_loss:4.576e+01 val_loss:2.178e+01  time:0m22s

 
  6%|▌         | 55/1000 [20:39<5:55:19, 22.56s/it]#epoch:55 stage:1 train_loss:4.402e+01 val_loss:2.239e+01  time:0m22s

 
  6%|▌         | 56/1000 [21:01<5:54:22, 22.52s/it]#epoch:56 stage:1 train_loss:4.264e+01 val_loss:2.034e+01  time:0m22s

 
  6%|▌         | 57/1000 [21:24<5:53:23, 22.49s/it]#epoch:57 stage:1 train_loss:4.358e+01 val_loss:2.217e+01  time:0m22s

 
  6%|▌         | 58/1000 [21:46<5:52:39, 22.46s/it]#epoch:58 stage:1 train_loss:4.457e+01 val_loss:2.199e+01  time:0m22s

 
  6%|▌         | 59/1000 [22:08<5:52:31, 22.48s/it]#epoch:59 stage:1 train_loss:4.579e+01 val_loss:2.120e+01  time:0m22s

 
  6%|▌         | 60/1000 [22:31<5:51:33, 22.44s/it]#epoch:60 stage:1 train_loss:4.160e+01 val_loss:2.116e+01  time:0m22s

 
  6%|▌         | 61/1000 [22:53<5:51:00, 22.43s/it]#epoch:61 stage:1 train_loss:4.136e+01 val_loss:2.177e+01  time:0m22s

 
  6%|▌         | 62/1000 [23:16<5:51:05, 22.46s/it]#epoch:62 stage:1 train_loss:3.751e+01 val_loss:2.174e+01  time:0m22s

 
  6%|▋         | 63/1000 [23:38<5:51:00, 22.48s/it]#epoch:63 stage:1 train_loss:3.670e+01 val_loss:2.822e+01  time:0m22s

 
  6%|▋         | 64/1000 [24:01<5:51:13, 22.51s/it]#epoch:64 stage:1 train_loss:3.372e+01 val_loss:2.942e+01  time:0m22s

 
  6%|▋         | 65/1000 [24:23<5:50:45, 22.51s/it]#epoch:65 stage:1 train_loss:3.179e+01 val_loss:2.807e+01  time:0m22s

 
  7%|▋         | 66/1000 [24:46<5:49:48, 22.47s/it]#epoch:66 stage:1 train_loss:2.840e+01 val_loss:2.729e+01  time:0m22s

 
  7%|▋         | 67/1000 [25:08<5:49:20, 22.47s/it]#epoch:67 stage:1 train_loss:2.640e+01 val_loss:2.886e+01  time:0m22s

 
  7%|▋         | 68/1000 [25:31<5:48:56, 22.46s/it]#epoch:68 stage:1 train_loss:2.449e+01 val_loss:3.070e+01  time:0m22s

 
  7%|▋         | 69/1000 [25:53<5:49:06, 22.50s/it]#epoch:69 stage:1 train_loss:2.479e+01 val_loss:3.329e+01  time:0m22s

 
  7%|▋         | 70/1000 [26:16<5:49:15, 22.53s/it]#epoch:70 stage:1 train_loss:2.392e+01 val_loss:2.697e+01  time:0m22s

 
  7%|▋         | 71/1000 [26:38<5:48:05, 22.48s/it]#epoch:71 stage:1 train_loss:2.345e+01 val_loss:2.314e+01  time:0m22s

 
  7%|▋         | 72/1000 [27:01<5:47:50, 22.49s/it]#epoch:72 stage:1 train_loss:2.136e+01 val_loss:3.144e+01  time:0m22s

 
  7%|▋         | 73/1000 [27:23<5:47:29, 22.49s/it]#epoch:73 stage:1 train_loss:2.163e+01 val_loss:2.905e+01  time:0m22s

 
  7%|▋         | 74/1000 [27:46<5:46:37, 22.46s/it]#epoch:74 stage:1 train_loss:2.120e+01 val_loss:2.472e+01  time:0m22s

 
  8%|▊         | 75/1000 [28:08<5:46:14, 22.46s/it]#epoch:75 stage:1 train_loss:1.865e+01 val_loss:3.257e+01  time:0m22s

 
  8%|▊         | 76/1000 [28:30<5:45:48, 22.46s/it]#epoch:76 stage:1 train_loss:1.552e+01 val_loss:3.717e+01  time:0m22s

 
  8%|▊         | 77/1000 [28:53<5:45:40, 22.47s/it]#epoch:77 stage:1 train_loss:1.593e+01 val_loss:3.303e+01  time:0m22s

 
  8%|▊         | 78/1000 [29:15<5:45:27, 22.48s/it]#epoch:78 stage:1 train_loss:1.528e+01 val_loss:4.072e+01  time:0m22s

 
  8%|▊         | 79/1000 [29:38<5:45:04, 22.48s/it]#epoch:79 stage:1 train_loss:2.573e+01 val_loss:2.491e+01  time:0m22s

 
  8%|▊         | 80/1000 [30:00<5:44:17, 22.45s/it]#epoch:80 stage:1 train_loss:2.040e+01 val_loss:2.653e+01  time:0m22s

 
  8%|▊         | 81/1000 [30:23<5:43:49, 22.45s/it]#epoch:81 stage:1 train_loss:1.736e+01 val_loss:2.563e+01  time:0m22s

 
  8%|▊         | 82/1000 [30:45<5:42:14, 22.37s/it]#epoch:82 stage:1 train_loss:1.610e+01 val_loss:3.088e+01  time:0m22s

 
  8%|▊         | 83/1000 [31:07<5:41:58, 22.38s/it]#epoch:83 stage:1 train_loss:1.538e+01 val_loss:3.616e+01  time:0m22s

 
  8%|▊         | 84/1000 [31:30<5:41:24, 22.36s/it]#epoch:84 stage:1 train_loss:1.502e+01 val_loss:3.183e+01  time:0m22s

 
  8%|▊         | 85/1000 [31:52<5:41:11, 22.37s/it]#epoch:85 stage:1 train_loss:1.272e+01 val_loss:3.813e+01  time:0m22s

 
  9%|▊         | 86/1000 [32:15<5:41:31, 22.42s/it]#epoch:86 stage:1 train_loss:1.124e+01 val_loss:4.057e+01  time:0m22s

 
  9%|▊         | 87/1000 [32:37<5:41:51, 22.47s/it]#epoch:87 stage:1 train_loss:1.163e+01 val_loss:3.625e+01  time:0m22s

 
  9%|▉         | 88/1000 [33:00<5:41:13, 22.45s/it]#epoch:88 stage:1 train_loss:9.890e+00 val_loss:4.295e+01  time:0m22s

 
  9%|▉         | 89/1000 [33:22<5:41:11, 22.47s/it]#epoch:89 stage:1 train_loss:9.619e+00 val_loss:4.016e+01  time:0m22s

 
  9%|▉         | 90/1000 [33:45<5:40:19, 22.44s/it]#epoch:90 stage:1 train_loss:1.010e+01 val_loss:3.920e+01  time:0m22s

 
  9%|▉         | 91/1000 [34:07<5:40:07, 22.45s/it]#epoch:91 stage:1 train_loss:1.276e+01 val_loss:3.921e+01  time:0m22s

 
  9%|▉         | 92/1000 [34:29<5:39:39, 22.44s/it]#epoch:92 stage:1 train_loss:1.692e+01 val_loss:3.021e+01  time:0m22s

 
  9%|▉         | 93/1000 [34:52<5:37:41, 22.34s/it]#epoch:93 stage:1 train_loss:1.152e+01 val_loss:3.683e+01  time:0m22s

 
  9%|▉         | 94/1000 [35:14<5:36:52, 22.31s/it]#epoch:94 stage:1 train_loss:8.476e+00 val_loss:4.092e+01  time:0m22s

 
 10%|▉         | 95/1000 [35:36<5:35:52, 22.27s/it]#epoch:95 stage:1 train_loss:1.405e+01 val_loss:3.781e+01  time:0m22s

 
 10%|▉         | 96/1000 [35:58<5:35:54, 22.29s/it]#epoch:96 stage:1 train_loss:1.411e+01 val_loss:3.371e+01  time:0m22s

 
 10%|▉         | 97/1000 [36:21<5:36:01, 22.33s/it]#epoch:97 stage:1 train_loss:7.633e+00 val_loss:3.796e+01  time:0m22s

 
 10%|▉         | 98/1000 [36:43<5:36:08, 22.36s/it]#epoch:98 stage:1 train_loss:6.086e+00 val_loss:4.086e+01  time:0m22s

 
 10%|▉         | 99/1000 [37:06<5:36:28, 22.41s/it]#epoch:99 stage:1 train_loss:4.558e+00 val_loss:3.973e+01  time:0m22s

 
 10%|█         | 100/1000 [37:28<5:36:42, 22.45s/it]#epoch:100 stage:1 train_loss:3.359e+00 val_loss:4.305e+01  time:0m22s

 
 10%|█         | 101/1000 [37:51<5:36:34, 22.46s/it]#epoch:101 stage:1 train_loss:2.906e+00 val_loss:4.363e+01  time:0m22s

 
 10%|█         | 102/1000 [38:13<5:35:38, 22.43s/it]#epoch:102 stage:1 train_loss:3.159e+00 val_loss:4.291e+01  time:0m22s

 
 10%|█         | 103/1000 [38:35<5:35:09, 22.42s/it]#epoch:103 stage:1 train_loss:3.402e+00 val_loss:4.347e+01  time:0m22s

 
 10%|█         | 104/1000 [38:58<5:34:45, 22.42s/it]#epoch:104 stage:1 train_loss:4.552e+00 val_loss:4.001e+01  time:0m22s

 
 10%|█         | 105/1000 [39:20<5:34:43, 22.44s/it]#epoch:105 stage:1 train_loss:4.377e+00 val_loss:4.008e+01  time:0m22s

 
 11%|█         | 106/1000 [39:43<5:34:42, 22.46s/it]#epoch:106 stage:1 train_loss:3.275e+00 val_loss:3.641e+01  time:0m22s

 
 11%|█         | 107/1000 [40:05<5:34:42, 22.49s/it]#epoch:107 stage:1 train_loss:2.959e+00 val_loss:3.523e+01  time:0m22s

 
 11%|█         | 108/1000 [40:28<5:33:55, 22.46s/it]#epoch:108 stage:1 train_loss:2.584e+00 val_loss:3.966e+01  time:0m22s

 
 11%|█         | 109/1000 [40:50<5:33:43, 22.47s/it]#epoch:109 stage:1 train_loss:1.783e+00 val_loss:4.152e+01  time:0m22s

 
 11%|█         | 110/1000 [41:13<5:33:26, 22.48s/it]#epoch:110 stage:1 train_loss:2.413e+00 val_loss:3.943e+01  time:0m22s

 
 11%|█         | 111/1000 [41:35<5:32:32, 22.44s/it]#epoch:111 stage:1 train_loss:1.584e+00 val_loss:4.487e+01  time:0m22s

 
 11%|█         | 112/1000 [41:58<5:31:54, 22.43s/it]#epoch:112 stage:1 train_loss:1.712e+00 val_loss:4.139e+01  time:0m22s

 
 11%|█▏        | 113/1000 [42:20<5:32:14, 22.47s/it]#epoch:113 stage:1 train_loss:1.249e+00 val_loss:4.342e+01  time:0m22s

 
 11%|█▏        | 114/1000 [42:43<5:31:55, 22.48s/it]#epoch:114 stage:1 train_loss:1.471e+00 val_loss:3.977e+01  time:0m22s

 
 12%|█▏        | 115/1000 [43:05<5:31:24, 22.47s/it]#epoch:115 stage:1 train_loss:1.245e+00 val_loss:4.449e+01  time:0m22s

 
 12%|█▏        | 116/1000 [43:28<5:31:03, 22.47s/it]#epoch:116 stage:1 train_loss:2.241e+00 val_loss:4.262e+01  time:0m22s

 
 12%|█▏        | 117/1000 [43:50<5:30:24, 22.45s/it]#epoch:117 stage:1 train_loss:1.343e+00 val_loss:4.892e+01  time:0m22s

 
 12%|█▏        | 118/1000 [44:12<5:30:18, 22.47s/it]#epoch:118 stage:1 train_loss:1.178e+00 val_loss:4.624e+01  time:0m22s

 
 12%|█▏        | 119/1000 [44:35<5:29:41, 22.45s/it]#epoch:119 stage:1 train_loss:9.811e-01 val_loss:4.516e+01  time:0m22s

 
 12%|█▏        | 120/1000 [44:57<5:29:35, 22.47s/it]#epoch:120 stage:1 train_loss:1.306e+00 val_loss:4.496e+01  time:0m22s

 
 12%|█▏        | 121/1000 [45:20<5:28:43, 22.44s/it]#epoch:121 stage:1 train_loss:8.059e-01 val_loss:4.647e+01  time:0m22s

 
 12%|█▏        | 122/1000 [45:42<5:28:37, 22.46s/it]#epoch:122 stage:1 train_loss:8.758e-01 val_loss:4.578e+01  time:0m22s

 
 12%|█▏        | 123/1000 [46:05<5:28:15, 22.46s/it]#epoch:123 stage:1 train_loss:8.130e-01 val_loss:4.745e+01  time:0m22s

 
 12%|█▏        | 124/1000 [46:27<5:28:03, 22.47s/it]#epoch:124 stage:1 train_loss:1.050e+00 val_loss:4.603e+01  time:0m22s

 
 12%|█▎        | 125/1000 [46:50<5:27:22, 22.45s/it]#epoch:125 stage:1 train_loss:6.962e-01 val_loss:4.992e+01  time:0m22s

 
 13%|█▎        | 126/1000 [47:12<5:26:42, 22.43s/it]#epoch:126 stage:1 train_loss:7.669e-01 val_loss:4.741e+01  time:0m22s

 
 13%|█▎        | 127/1000 [47:35<5:26:50, 22.46s/it]#epoch:127 stage:1 train_loss:7.390e-01 val_loss:5.061e+01  time:0m22s

 
 13%|█▎        | 128/1000 [47:57<5:26:37, 22.47s/it]#epoch:128 stage:1 train_loss:1.010e+00 val_loss:4.815e+01  time:0m22s

 
 13%|█▎        | 129/1000 [48:20<5:26:42, 22.51s/it]#epoch:129 stage:1 train_loss:6.073e-01 val_loss:5.144e+01  time:0m22s

 
 13%|█▎        | 130/1000 [48:42<5:25:24, 22.44s/it]#epoch:130 stage:1 train_loss:5.968e-01 val_loss:4.864e+01  time:0m22s

 
 13%|█▎        | 131/1000 [49:04<5:24:54, 22.43s/it]#epoch:131 stage:1 train_loss:5.212e-01 val_loss:5.331e+01  time:0m22s

 
 13%|█▎        | 132/1000 [49:27<5:24:34, 22.44s/it]#epoch:132 stage:1 train_loss:5.140e-01 val_loss:5.029e+01  time:0m22s

 
 13%|█▎        | 133/1000 [49:49<5:24:25, 22.45s/it]#epoch:133 stage:1 train_loss:5.153e-01 val_loss:5.299e+01  time:0m22s

 
 13%|█▎        | 134/1000 [50:12<5:23:41, 22.43s/it]#epoch:134 stage:1 train_loss:7.201e-01 val_loss:4.980e+01  time:0m22s

 
 14%|█▎        | 135/1000 [50:34<5:23:51, 22.46s/it]#epoch:135 stage:1 train_loss:4.432e-01 val_loss:5.463e+01  time:0m22s

 
 14%|█▎        | 136/1000 [50:57<5:23:09, 22.44s/it]#epoch:136 stage:1 train_loss:3.959e-01 val_loss:5.397e+01  time:0m22s

 
 14%|█▎        | 137/1000 [51:19<5:23:01, 22.46s/it]#epoch:137 stage:1 train_loss:4.192e-01 val_loss:5.447e+01  time:0m22s

 
 14%|█▍        | 138/1000 [51:41<5:22:40, 22.46s/it]#epoch:138 stage:1 train_loss:5.102e-01 val_loss:5.345e+01  time:0m22s

 
 14%|█▍        | 139/1000 [52:04<5:21:04, 22.37s/it]#epoch:139 stage:1 train_loss:5.275e-01 val_loss:5.509e+01  time:0m22s

 
 14%|█▍        | 140/1000 [52:26<5:19:30, 22.29s/it]#epoch:140 stage:1 train_loss:9.001e-01 val_loss:5.132e+01  time:0m22s

 
 14%|█▍        | 141/1000 [52:48<5:20:01, 22.35s/it]#epoch:141 stage:1 train_loss:4.677e-01 val_loss:5.497e+01  time:0m22s

 
 14%|█▍        | 142/1000 [53:11<5:20:33, 22.42s/it]#epoch:142 stage:1 train_loss:4.571e-01 val_loss:5.528e+01  time:0m22s

 
 14%|█▍        | 143/1000 [53:33<5:20:32, 22.44s/it]#epoch:143 stage:1 train_loss:3.666e-01 val_loss:5.720e+01  time:0m22s

 
 14%|█▍        | 144/1000 [53:56<5:20:13, 22.45s/it]#epoch:144 stage:1 train_loss:4.197e-01 val_loss:5.417e+01  time:0m22s

 
 14%|█▍        | 145/1000 [54:18<5:19:44, 22.44s/it]#epoch:145 stage:1 train_loss:3.069e-01 val_loss:5.801e+01  time:0m22s

 
 15%|█▍        | 146/1000 [54:41<5:19:34, 22.45s/it]#epoch:146 stage:1 train_loss:3.074e-01 val_loss:5.646e+01  time:0m22s

 
 15%|█▍        | 147/1000 [55:03<5:18:25, 22.40s/it]#epoch:147 stage:1 train_loss:3.734e-01 val_loss:5.824e+01  time:0m22s

 
 15%|█▍        | 148/1000 [55:25<5:18:37, 22.44s/it]#epoch:148 stage:1 train_loss:4.956e-01 val_loss:5.320e+01  time:0m22s

 
 15%|█▍        | 149/1000 [55:48<5:17:41, 22.40s/it]#epoch:149 stage:1 train_loss:2.936e-01 val_loss:6.040e+01  time:0m22s

 
 15%|█▌        | 150/1000 [56:10<5:17:54, 22.44s/it]#epoch:150 stage:1 train_loss:2.640e-01 val_loss:5.780e+01  time:0m22s

 
 15%|█▌        | 151/1000 [56:33<5:17:51, 22.46s/it]#epoch:151 stage:1 train_loss:2.729e-01 val_loss:6.142e+01  time:0m22s

 
 15%|█▌        | 152/1000 [56:55<5:17:17, 22.45s/it]#epoch:152 stage:1 train_loss:3.114e-01 val_loss:5.666e+01  time:0m22s

 
 15%|█▌        | 153/1000 [57:18<5:16:59, 22.46s/it]#epoch:153 stage:1 train_loss:2.691e-01 val_loss:6.003e+01  time:0m22s

 
 15%|█▌        | 154/1000 [57:40<5:16:33, 22.45s/it]#epoch:154 stage:1 train_loss:3.194e-01 val_loss:5.798e+01  time:0m22s

 
 16%|█▌        | 155/1000 [58:03<5:16:43, 22.49s/it]#epoch:155 stage:1 train_loss:2.258e-01 val_loss:6.063e+01  time:0m22s

 
 16%|█▌        | 156/1000 [58:25<5:16:15, 22.48s/it]#epoch:156 stage:1 train_loss:2.662e-01 val_loss:6.107e+01  time:0m22s

 
 16%|█▌        | 157/1000 [58:48<5:16:06, 22.50s/it]#epoch:157 stage:1 train_loss:2.453e-01 val_loss:5.949e+01  time:0m22s

 
 16%|█▌        | 158/1000 [59:10<5:14:55, 22.44s/it]#epoch:158 stage:1 train_loss:3.132e-01 val_loss:6.122e+01  time:0m22s

 
 16%|█▌        | 159/1000 [59:33<5:14:37, 22.45s/it]#epoch:159 stage:1 train_loss:2.956e-01 val_loss:5.872e+01  time:0m22s

 
 16%|█▌        | 160/1000 [59:55<5:14:08, 22.44s/it]#epoch:160 stage:1 train_loss:3.164e-01 val_loss:6.141e+01  time:0m22s

 
 16%|█▌        | 161/1000 [1:00:17<5:13:57, 22.45s/it]#epoch:161 stage:1 train_loss:3.122e-01 val_loss:5.617e+01  time:0m22s

 
 16%|█▌        | 162/1000 [1:00:40<5:13:18, 22.43s/it]#epoch:162 stage:1 train_loss:2.722e-01 val_loss:6.203e+01  time:0m22s

 
 16%|█▋        | 163/1000 [1:01:02<5:13:16, 22.46s/it]#epoch:163 stage:1 train_loss:2.499e-01 val_loss:5.376e+01  time:0m22s

 
 16%|█▋        | 164/1000 [1:01:25<5:12:18, 22.41s/it]#epoch:164 stage:1 train_loss:1.908e-01 val_loss:5.667e+01  time:0m22s

 
 16%|█▋        | 165/1000 [1:01:47<5:12:09, 22.43s/it]#epoch:165 stage:1 train_loss:1.538e-01 val_loss:5.737e+01  time:0m22s

 
 17%|█▋        | 166/1000 [1:02:10<5:11:38, 22.42s/it]#epoch:166 stage:1 train_loss:1.435e-01 val_loss:5.878e+01  time:0m22s

 
 17%|█▋        | 167/1000 [1:02:32<5:10:37, 22.37s/it]#epoch:167 stage:1 train_loss:1.283e-01 val_loss:5.895e+01  time:0m22s

 
 17%|█▋        | 168/1000 [1:02:54<5:10:37, 22.40s/it]#epoch:168 stage:1 train_loss:1.318e-01 val_loss:5.924e+01  time:0m22s

 
 17%|█▋        | 169/1000 [1:03:17<5:10:32, 22.42s/it]#epoch:169 stage:1 train_loss:1.262e-01 val_loss:5.883e+01  time:0m22s

 
 17%|█▋        | 170/1000 [1:03:39<5:10:14, 22.43s/it]#epoch:170 stage:1 train_loss:1.256e-01 val_loss:5.911e+01  time:0m22s

 
 17%|█▋        | 171/1000 [1:04:02<5:10:09, 22.45s/it]#epoch:171 stage:1 train_loss:1.443e-01 val_loss:6.149e+01  time:0m22s

 
 17%|█▋        | 172/1000 [1:04:24<5:10:03, 22.47s/it]#epoch:172 stage:1 train_loss:1.332e-01 val_loss:6.045e+01  time:0m22s

 
 17%|█▋        | 173/1000 [1:04:47<5:09:38, 22.47s/it]#epoch:173 stage:1 train_loss:1.243e-01 val_loss:6.230e+01  time:0m22s

 
 17%|█▋        | 174/1000 [1:05:09<5:09:09, 22.46s/it]#epoch:174 stage:1 train_loss:1.339e-01 val_loss:6.232e+01  time:0m22s

 
 18%|█▊        | 175/1000 [1:05:31<5:08:05, 22.41s/it]#epoch:175 stage:1 train_loss:1.110e-01 val_loss:6.274e+01  time:0m22s

 
 18%|█▊        | 176/1000 [1:05:54<5:07:22, 22.38s/it]#epoch:176 stage:1 train_loss:1.069e-01 val_loss:6.262e+01  time:0m22s

 
 18%|█▊        | 177/1000 [1:06:16<5:07:16, 22.40s/it]#epoch:177 stage:1 train_loss:1.067e-01 val_loss:6.248e+01  time:0m22s

 
 18%|█▊        | 178/1000 [1:06:39<5:07:24, 22.44s/it]#epoch:178 stage:1 train_loss:1.065e-01 val_loss:6.334e+01  time:0m22s

 
 18%|█▊        | 179/1000 [1:07:01<5:07:24, 22.47s/it]#epoch:179 stage:1 train_loss:1.011e-01 val_loss:6.459e+01  time:0m22s

 
 18%|█▊        | 180/1000 [1:07:24<5:06:54, 22.46s/it]#epoch:180 stage:1 train_loss:1.046e-01 val_loss:6.409e+01  time:0m22s

 
 18%|█▊        | 181/1000 [1:07:46<5:05:55, 22.41s/it]#epoch:181 stage:1 train_loss:9.557e-02 val_loss:6.384e+01  time:0m22s

 
 18%|█▊        | 182/1000 [1:08:08<5:06:01, 22.45s/it]#epoch:182 stage:1 train_loss:1.030e-01 val_loss:6.385e+01  time:0m22s

 
 18%|█▊        | 183/1000 [1:08:31<5:05:27, 22.43s/it]#epoch:183 stage:1 train_loss:9.713e-02 val_loss:6.570e+01  time:0m22s

 
 18%|█▊        | 184/1000 [1:08:53<5:05:19, 22.45s/it]#epoch:184 stage:1 train_loss:1.038e-01 val_loss:6.554e+01  time:0m22s

 
 18%|█▊        | 185/1000 [1:09:16<5:04:53, 22.45s/it]#epoch:185 stage:1 train_loss:1.037e-01 val_loss:6.572e+01  time:0m22s

 
 19%|█▊        | 186/1000 [1:09:38<5:04:14, 22.43s/it]#epoch:186 stage:1 train_loss:9.711e-02 val_loss:6.453e+01  time:0m22s

 
 19%|█▊        | 187/1000 [1:10:01<5:04:05, 22.44s/it]#epoch:187 stage:1 train_loss:8.234e-02 val_loss:6.410e+01  time:0m22s

 
 19%|█▉        | 188/1000 [1:10:23<5:03:44, 22.44s/it]#epoch:188 stage:1 train_loss:8.034e-02 val_loss:6.303e+01  time:0m22s

 
 19%|█▉        | 189/1000 [1:10:46<5:03:19, 22.44s/it]#epoch:189 stage:1 train_loss:8.637e-02 val_loss:6.550e+01  time:0m22s

 
 19%|█▉        | 190/1000 [1:11:08<5:02:35, 22.41s/it]#epoch:190 stage:1 train_loss:8.170e-02 val_loss:6.525e+01  time:0m22s

 
 19%|█▉        | 191/1000 [1:11:30<5:02:35, 22.44s/it]#epoch:191 stage:1 train_loss:8.085e-02 val_loss:6.557e+01  time:0m22s

 
 19%|█▉        | 192/1000 [1:11:53<5:02:40, 22.48s/it]#epoch:192 stage:1 train_loss:7.474e-02 val_loss:6.600e+01  time:0m22s

 
 19%|█▉        | 193/1000 [1:12:15<5:02:16, 22.47s/it]#epoch:193 stage:1 train_loss:7.063e-02 val_loss:6.526e+01  time:0m22s

 
 19%|█▉        | 194/1000 [1:12:38<5:01:30, 22.45s/it]#epoch:194 stage:1 train_loss:7.380e-02 val_loss:6.467e+01  time:0m22s

 
 20%|█▉        | 195/1000 [1:13:00<5:00:59, 22.43s/it]#epoch:195 stage:1 train_loss:6.853e-02 val_loss:6.400e+01  time:0m22s

 
 20%|█▉        | 196/1000 [1:13:23<5:00:16, 22.41s/it]#epoch:196 stage:1 train_loss:6.581e-02 val_loss:6.588e+01  time:0m22s

 
 20%|█▉        | 197/1000 [1:13:45<4:59:39, 22.39s/it]#epoch:197 stage:1 train_loss:6.311e-02 val_loss:6.502e+01  time:0m22s

 
 20%|█▉        | 198/1000 [1:14:07<4:59:10, 22.38s/it]#epoch:198 stage:1 train_loss:6.008e-02 val_loss:6.483e+01  time:0m22s

 
 20%|█▉        | 199/1000 [1:14:30<4:59:07, 22.41s/it]#epoch:199 stage:1 train_loss:5.739e-02 val_loss:6.583e+01  time:0m22s

 
 20%|██        | 200/1000 [1:14:52<4:59:24, 22.46s/it]#epoch:200 stage:1 train_loss:5.924e-02 val_loss:6.621e+01  time:0m22s

 
 20%|██        | 201/1000 [1:15:15<4:59:05, 22.46s/it]#epoch:201 stage:1 train_loss:5.923e-02 val_loss:6.640e+01  time:0m22s

 
 20%|██        | 202/1000 [1:15:37<4:58:45, 22.46s/it]#epoch:202 stage:1 train_loss:5.644e-02 val_loss:6.590e+01  time:0m22s

 
 20%|██        | 203/1000 [1:16:00<4:58:41, 22.49s/it]#epoch:203 stage:1 train_loss:5.593e-02 val_loss:6.716e+01  time:0m22s

 
 20%|██        | 204/1000 [1:16:22<4:57:12, 22.40s/it]#epoch:204 stage:1 train_loss:5.458e-02 val_loss:6.601e+01  time:0m22s

 
 20%|██        | 205/1000 [1:16:44<4:56:11, 22.35s/it]#epoch:205 stage:1 train_loss:5.148e-02 val_loss:6.651e+01  time:0m22s

 
 21%|██        | 206/1000 [1:17:07<4:55:58, 22.37s/it]#epoch:206 stage:1 train_loss:5.512e-02 val_loss:6.573e+01  time:0m22s

 
 21%|██        | 207/1000 [1:17:29<4:55:51, 22.39s/it]#epoch:207 stage:1 train_loss:5.321e-02 val_loss:6.668e+01  time:0m22s

 
 21%|██        | 208/1000 [1:17:52<4:56:16, 22.44s/it]#epoch:208 stage:1 train_loss:5.105e-02 val_loss:6.606e+01  time:0m22s

 
 21%|██        | 209/1000 [1:18:14<4:56:06, 22.46s/it]#epoch:209 stage:1 train_loss:4.788e-02 val_loss:6.567e+01  time:0m22s

 
 21%|██        | 210/1000 [1:18:37<4:55:49, 22.47s/it]#epoch:210 stage:1 train_loss:5.046e-02 val_loss:6.598e+01  time:0m22s

 
 21%|██        | 211/1000 [1:18:59<4:54:58, 22.43s/it]#epoch:211 stage:1 train_loss:5.168e-02 val_loss:6.720e+01  time:0m22s

 
 21%|██        | 212/1000 [1:19:21<4:54:43, 22.44s/it]#epoch:212 stage:1 train_loss:5.004e-02 val_loss:6.939e+01  time:0m22s

 
 21%|██▏       | 213/1000 [1:19:44<4:54:19, 22.44s/it]#epoch:213 stage:1 train_loss:4.633e-02 val_loss:6.819e+01  time:0m22s

 
 21%|██▏       | 214/1000 [1:20:06<4:53:33, 22.41s/it]#epoch:214 stage:1 train_loss:4.616e-02 val_loss:6.815e+01  time:0m22s

 
 22%|██▏       | 215/1000 [1:20:28<4:52:25, 22.35s/it]#epoch:215 stage:1 train_loss:4.586e-02 val_loss:6.826e+01  time:0m22s

 
 22%|██▏       | 216/1000 [1:20:51<4:52:41, 22.40s/it]#epoch:216 stage:1 train_loss:4.716e-02 val_loss:6.781e+01  time:0m22s

 
 22%|██▏       | 217/1000 [1:21:13<4:52:22, 22.40s/it]#epoch:217 stage:1 train_loss:4.496e-02 val_loss:6.834e+01  time:0m22s

 
 22%|██▏       | 218/1000 [1:21:36<4:52:29, 22.44s/it]#epoch:218 stage:1 train_loss:4.598e-02 val_loss:6.987e+01  time:0m22s

 
 22%|██▏       | 219/1000 [1:21:58<4:52:19, 22.46s/it]#epoch:219 stage:1 train_loss:4.064e-02 val_loss:6.907e+01  time:0m22s

 
 22%|██▏       | 220/1000 [1:22:21<4:52:03, 22.47s/it]#epoch:220 stage:1 train_loss:4.084e-02 val_loss:6.880e+01  time:0m22s

 
 22%|██▏       | 221/1000 [1:22:43<4:51:43, 22.47s/it]#epoch:221 stage:1 train_loss:3.876e-02 val_loss:6.946e+01  time:0m22s

 
 22%|██▏       | 222/1000 [1:23:06<4:51:21, 22.47s/it]#epoch:222 stage:1 train_loss:4.086e-02 val_loss:6.914e+01  time:0m22s

 
 22%|██▏       | 223/1000 [1:23:28<4:50:20, 22.42s/it]#epoch:223 stage:1 train_loss:4.012e-02 val_loss:6.861e+01  time:0m22s

 
 22%|██▏       | 224/1000 [1:23:50<4:47:47, 22.25s/it]#epoch:224 stage:1 train_loss:3.755e-02 val_loss:6.942e+01  time:0m22s

 
 22%|██▎       | 225/1000 [1:24:12<4:46:49, 22.21s/it]#epoch:225 stage:1 train_loss:4.039e-02 val_loss:6.881e+01  time:0m22s

 
 23%|██▎       | 226/1000 [1:24:34<4:46:40, 22.22s/it]#epoch:226 stage:1 train_loss:4.199e-02 val_loss:6.974e+01  time:0m22s

 
 23%|██▎       | 227/1000 [1:24:57<4:46:41, 22.25s/it]#epoch:227 stage:1 train_loss:4.018e-02 val_loss:6.966e+01  time:0m22s

 
 23%|██▎       | 228/1000 [1:25:19<4:46:22, 22.26s/it]#epoch:228 stage:1 train_loss:3.764e-02 val_loss:6.833e+01  time:0m22s

 
 23%|██▎       | 229/1000 [1:25:41<4:46:46, 22.32s/it]#epoch:229 stage:1 train_loss:3.584e-02 val_loss:6.876e+01  time:0m22s

 
 23%|██▎       | 230/1000 [1:26:04<4:46:25, 22.32s/it]#epoch:230 stage:1 train_loss:4.360e-02 val_loss:6.982e+01  time:0m22s

 
 23%|██▎       | 231/1000 [1:26:26<4:46:09, 22.33s/it]#epoch:231 stage:1 train_loss:4.104e-02 val_loss:7.190e+01  time:0m22s

 
 23%|██▎       | 232/1000 [1:26:48<4:45:47, 22.33s/it]#epoch:232 stage:1 train_loss:3.346e-02 val_loss:6.974e+01  time:0m22s

 
 23%|██▎       | 233/1000 [1:27:11<4:45:29, 22.33s/it]#epoch:233 stage:1 train_loss:3.478e-02 val_loss:6.897e+01  time:0m22s

 
 23%|██▎       | 234/1000 [1:27:33<4:43:17, 22.19s/it]#epoch:234 stage:1 train_loss:3.301e-02 val_loss:6.990e+01  time:0m22s

 
 24%|██▎       | 235/1000 [1:27:55<4:42:22, 22.15s/it]#epoch:235 stage:1 train_loss:3.446e-02 val_loss:7.090e+01  time:0m22s

 
 24%|██▎       | 236/1000 [1:28:17<4:43:39, 22.28s/it]#epoch:236 stage:1 train_loss:3.463e-02 val_loss:7.012e+01  time:0m22s

 
 24%|██▎       | 237/1000 [1:28:40<4:44:07, 22.34s/it]#epoch:237 stage:1 train_loss:3.393e-02 val_loss:7.072e+01  time:0m22s

 
 24%|██▍       | 238/1000 [1:29:02<4:44:39, 22.41s/it]#epoch:238 stage:1 train_loss:3.691e-02 val_loss:7.119e+01  time:0m22s

 
 24%|██▍       | 239/1000 [1:29:25<4:44:09, 22.40s/it]#epoch:239 stage:1 train_loss:3.804e-02 val_loss:6.981e+01  time:0m22s

 
 24%|██▍       | 240/1000 [1:29:47<4:43:31, 22.38s/it]#epoch:240 stage:1 train_loss:3.054e-02 val_loss:7.232e+01  time:0m22s

 
 24%|██▍       | 241/1000 [1:30:09<4:43:27, 22.41s/it]#epoch:241 stage:1 train_loss:2.965e-02 val_loss:7.161e+01  time:0m22s

 
 24%|██▍       | 242/1000 [1:30:32<4:42:58, 22.40s/it]#epoch:242 stage:1 train_loss:2.990e-02 val_loss:7.091e+01  time:0m22s

 
 24%|██▍       | 243/1000 [1:30:54<4:43:16, 22.45s/it]#epoch:243 stage:1 train_loss:2.852e-02 val_loss:7.006e+01  time:0m22s

 
 24%|██▍       | 244/1000 [1:31:17<4:42:12, 22.40s/it]#epoch:244 stage:1 train_loss:3.000e-02 val_loss:6.967e+01  time:0m22s

 
 24%|██▍       | 245/1000 [1:31:39<4:42:17, 22.43s/it]#epoch:245 stage:1 train_loss:2.886e-02 val_loss:7.025e+01  time:0m22s

 
 25%|██▍       | 246/1000 [1:32:02<4:41:37, 22.41s/it]#epoch:246 stage:1 train_loss:3.035e-02 val_loss:7.210e+01  time:0m22s

 
 25%|██▍       | 247/1000 [1:32:24<4:41:30, 22.43s/it]#epoch:247 stage:1 train_loss:2.816e-02 val_loss:7.164e+01  time:0m22s

 
 25%|██▍       | 248/1000 [1:32:46<4:41:14, 22.44s/it]#epoch:248 stage:1 train_loss:2.856e-02 val_loss:7.143e+01  time:0m22s

 
 25%|██▍       | 249/1000 [1:33:09<4:40:55, 22.44s/it]#epoch:249 stage:1 train_loss:2.736e-02 val_loss:7.207e+01  time:0m22s

 
 25%|██▌       | 250/1000 [1:33:31<4:40:51, 22.47s/it]#epoch:250 stage:1 train_loss:2.780e-02 val_loss:7.127e+01  time:0m22s

 
 25%|██▌       | 251/1000 [1:33:54<4:40:25, 22.46s/it]#epoch:251 stage:1 train_loss:2.618e-02 val_loss:7.055e+01  time:0m22s

 
 25%|██▌       | 252/1000 [1:34:16<4:40:13, 22.48s/it]#epoch:252 stage:1 train_loss:2.520e-02 val_loss:7.349e+01  time:0m22s

 
 25%|██▌       | 253/1000 [1:34:39<4:39:05, 22.42s/it]#epoch:253 stage:1 train_loss:2.464e-02 val_loss:7.071e+01  time:0m22s

 
 25%|██▌       | 254/1000 [1:35:01<4:38:46, 22.42s/it]#epoch:254 stage:1 train_loss:2.473e-02 val_loss:7.186e+01  time:0m22s

 
 26%|██▌       | 255/1000 [1:35:24<4:38:28, 22.43s/it]#epoch:255 stage:1 train_loss:2.658e-02 val_loss:7.126e+01  time:0m22s

 
 26%|██▌       | 256/1000 [1:35:46<4:38:22, 22.45s/it]#epoch:256 stage:1 train_loss:2.474e-02 val_loss:7.241e+01  time:0m22s

 
 26%|██▌       | 257/1000 [1:36:08<4:37:36, 22.42s/it]#epoch:257 stage:1 train_loss:2.423e-02 val_loss:7.171e+01  time:0m22s

 
 26%|██▌       | 258/1000 [1:36:31<4:37:28, 22.44s/it]#epoch:258 stage:1 train_loss:2.529e-02 val_loss:7.298e+01  time:0m22s

 
 26%|██▌       | 259/1000 [1:36:53<4:37:10, 22.44s/it]#epoch:259 stage:1 train_loss:2.346e-02 val_loss:7.232e+01  time:0m22s

 
 26%|██▌       | 260/1000 [1:37:16<4:37:04, 22.47s/it]#epoch:260 stage:1 train_loss:2.559e-02 val_loss:7.005e+01  time:0m22s

 
 26%|██▌       | 261/1000 [1:37:38<4:36:39, 22.46s/it]#epoch:261 stage:1 train_loss:2.525e-02 val_loss:7.280e+01  time:0m22s

 
 26%|██▌       | 262/1000 [1:38:00<4:35:05, 22.37s/it]#epoch:262 stage:1 train_loss:2.421e-02 val_loss:7.272e+01  time:0m22s

 
 26%|██▋       | 263/1000 [1:38:23<4:34:54, 22.38s/it]#epoch:263 stage:1 train_loss:2.401e-02 val_loss:7.221e+01  time:0m22s

 
 26%|██▋       | 264/1000 [1:38:45<4:35:01, 22.42s/it]#epoch:264 stage:1 train_loss:2.358e-02 val_loss:7.197e+01  time:0m22s

 
 26%|██▋       | 265/1000 [1:39:08<4:35:18, 22.47s/it]#epoch:265 stage:1 train_loss:2.489e-02 val_loss:7.378e+01  time:0m22s

 
 27%|██▋       | 266/1000 [1:39:30<4:34:52, 22.47s/it]#epoch:266 stage:1 train_loss:2.106e-02 val_loss:7.229e+01  time:0m22s

 
 27%|██▋       | 267/1000 [1:39:53<4:34:44, 22.49s/it]#epoch:267 stage:1 train_loss:2.129e-02 val_loss:7.308e+01  time:0m22s

 
 27%|██▋       | 268/1000 [1:40:16<4:34:32, 22.50s/it]#epoch:268 stage:1 train_loss:2.340e-02 val_loss:7.274e+01  time:0m22s

 
 27%|██▋       | 269/1000 [1:40:38<4:33:57, 22.49s/it]#epoch:269 stage:1 train_loss:2.169e-02 val_loss:7.370e+01  time:0m22s

 
 27%|██▋       | 270/1000 [1:41:00<4:33:18, 22.46s/it]#epoch:270 stage:1 train_loss:2.150e-02 val_loss:7.222e+01  time:0m22s

 
 27%|██▋       | 271/1000 [1:41:23<4:32:06, 22.40s/it]#epoch:271 stage:1 train_loss:2.070e-02 val_loss:7.269e+01  time:0m22s

 
 27%|██▋       | 272/1000 [1:41:45<4:31:51, 22.41s/it]#epoch:272 stage:1 train_loss:2.295e-02 val_loss:7.441e+01  time:0m22s

 
 27%|██▋       | 273/1000 [1:42:08<4:31:58, 22.45s/it]#epoch:273 stage:1 train_loss:2.162e-02 val_loss:7.264e+01  time:0m22s

 
 27%|██▋       | 274/1000 [1:42:30<4:31:28, 22.44s/it]#epoch:274 stage:1 train_loss:2.343e-02 val_loss:7.174e+01  time:0m22s

 
 28%|██▊       | 275/1000 [1:42:52<4:30:57, 22.42s/it]#epoch:275 stage:1 train_loss:2.012e-02 val_loss:7.345e+01  time:0m22s

 
 28%|██▊       | 276/1000 [1:43:15<4:30:09, 22.39s/it]#epoch:276 stage:1 train_loss:2.119e-02 val_loss:7.314e+01  time:0m22s

 
 28%|██▊       | 277/1000 [1:43:37<4:30:14, 22.43s/it]#epoch:277 stage:1 train_loss:2.061e-02 val_loss:7.341e+01  time:0m22s

 
 28%|██▊       | 278/1000 [1:44:00<4:30:07, 22.45s/it]#epoch:278 stage:1 train_loss:2.177e-02 val_loss:7.303e+01  time:0m22s

 
 28%|██▊       | 279/1000 [1:44:22<4:30:05, 22.48s/it]#epoch:279 stage:1 train_loss:1.915e-02 val_loss:7.407e+01  time:0m22s

 
 28%|██▊       | 280/1000 [1:44:45<4:29:30, 22.46s/it]#epoch:280 stage:1 train_loss:1.936e-02 val_loss:7.387e+01  time:0m22s

 
 28%|██▊       | 281/1000 [1:45:07<4:28:42, 22.42s/it]#epoch:281 stage:1 train_loss:1.908e-02 val_loss:7.357e+01  time:0m22s

 
 28%|██▊       | 282/1000 [1:45:29<4:28:18, 22.42s/it]#epoch:282 stage:1 train_loss:2.004e-02 val_loss:7.321e+01  time:0m22s

 
 28%|██▊       | 283/1000 [1:45:45<4:02:24, 20.28s/it]#epoch:283 stage:1 train_loss:1.884e-02 val_loss:7.373e+01  time:0m15s

 
